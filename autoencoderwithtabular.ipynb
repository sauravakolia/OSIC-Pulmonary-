{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import copy\n\nfrom datetime import timedelta, datetime\nimport imageio\nimport matplotlib.pyplot as plt\nfrom matplotlib import cm\nimport multiprocessing\nimport numpy as np\nimport os\nfrom pathlib import Path\nimport pydicom\nimport pytest\nimport scipy.ndimage\nimport scipy.ndimage as ndimage\nfrom scipy.ndimage.interpolation import zoom\nfrom skimage import measure, morphology, segmentation\nfrom time import time, sleep\nfrom tqdm import trange, tqdm\nimport torch                                                                                           \nimport torch.nn as nn\nimport torch.nn.functional as F                                   \nfrom torch.utils.data import Dataset, random_split, DistributedSampler, DataLoader\nfrom torch.utils.tensorboard import SummaryWriter\nfrom torchvision import transforms\nimport warnings                        \nimport pandas as pd\n\nimport os\nimport copy\nfrom datetime import datetime, timedelta\nimport matplotlib.pyplot as plt\nfrom matplotlib import cm\nimport numpy as np\nimport pandas as pd\nfrom pathlib import Path\nimport pickle\nimport pydicom\nfrom sklearn.model_selection import GroupKFold, GroupShuffleSplit\nfrom torch.utils.data import Dataset\nfrom tqdm import tqdm\nimport torch\nfrom torch.utils.data import DataLoader, Subset\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom tqdm import trange\nfrom time import time\nimport warnings\nfrom scipy.ndimage.interpolation import zoom\nfrom enum import Enum\nfrom torchvision import transforms\nfrom skimage.measure import label, regionprops\nfrom skimage.segmentation import clear_border\nimport pytest\nfrom torch.optim.lr_scheduler import StepLR\n\nfrom joblib import Parallel, delayed\nimport gc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"root_dir = '/kaggle/input/osic-pulmonary-fibrosis-progression/'\n# root_dir=\"/kaggle/input/osic-pulmonary-fibrosis-progression/\"\ntest_dir = '/kaggle/input/osic-pulmonary-fibrosis-progression/test/'\nmodel_dir = '/kaggle/working/'\n# model_file = '../input/latentspace-weights/diophantus.pt'\nresize_dims = (40, 256, 256)\nclip_bounds = (-1000, 200)\nwatershed_iterations = 1\npre_calculated_mean = 0.02865046213070556\nlatent_features = 10\nbatch_size = 32\nlearning_rate = 3e-03\nnum_epochs = 150\nval_size = 0.2\ntensorboard_dir = '/kaggle/working/runs/'\n\npretrained_weigths_dir = '/kaggle/input/latentspace-weights/'\npretrained_ae_weigths = os.path.join(pretrained_weigths_dir,'diophantus.pt')\ncache_dir = '/kaggle/input/osic-preprocrsseddata'\nlatent_dir = '/kaggle/working/latent'\n\nos.mkdir(os.path.join(model_dir,'latent'))\n\ntest_cache_dir=\"kaggle/working/test_cache\"\nos.mkdir(os.path.join(model_dir,'test_cache'))\n\ntest_latent_dir=\"kaggle/working/test_latent\"\nos.mkdir(os.path.join(model_dir,'test_latent'))\ntest_size=0.2\nbatch_size = 32\nlearning_rate = 3e-03\nnum_epochs =25\nquantiles = (0.2, 0.5, 0.8)\nmodel_name ='cauchy'\n\nnum_kfolds = 5\n# batch_size = 32\n# learning_rate = 3e-03\n# num_epochs = 1000\nes_patience = 20\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pydicom\nfrom fastai2.basics           import *\nfrom fastai2.medical.imaging  import *\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df=pd.read_csv(\"../input/osic-pulmonary-fibrosis-progression/train.csv\")\n# df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df.drop_duplicates(keep=False, inplace=True, subset=['Patient', 'Weeks'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"import pickle\nclass ClinicalDataset(Dataset):\n    def __init__(self, root_dir, ctscans_dir, mode, transform=None,\n                 cache_dir=None):\n        self.transform = transform\n        self.mode = mode\n        self.ctscans_dir = ctscans_dir\n        self.cache_dir = None if cache_dir is None else cache_dir\n\n        # If cache_dir is set, use cached values...\n        if cache_dir is not None:\n            self.raw = pd.read_csv(os.path.join(self.cache_dir,f'tabular_{self.mode}.csv'))\n#             self.raw=self.raw.drop(self.raw.loc[self.raw['Patient']=='ID00108637202209619669361']\n#                             .index).reset_index(drop=True)\n            with open(os.path.join(self.cache_dir,'features_list.pkl'), \"rb\") as fp:\n                self.FE = pickle.load(fp)\n            return\n\n        # ...otherwise, pre-process\n        tr = pd.read_csv(os.path.join(root_dir,\"train.csv\"))\n#         tr=tr.drop(tr.loc[tr['Patient']=='ID00108637202209619669361']\n#                             .index).reset_index(drop=True)\n        tr.drop_duplicates(keep=False, inplace=True, subset=['Patient', 'Weeks'])\n        chunk = pd.read_csv(os.path.join(root_dir,\"test.csv\"))\n\n        sub = pd.read_csv(os.path.join(root_dir,\"sample_submission.csv\"))\n        sub['Patient'] = sub['Patient_Week'].apply(lambda x: x.split('_')[0])\n        sub['Weeks'] = sub['Patient_Week'].apply(lambda x: int(x.split('_')[-1]))\n        sub = sub[['Patient', 'Weeks', 'Confidence', 'Patient_Week']]\n        sub = sub.merge(chunk.drop('Weeks', axis=1), on=\"Patient\")\n\n        tr['WHERE'] = 'train'\n        chunk['WHERE'] = 'val'\n        sub['WHERE'] = 'test'\n        data = tr.append([chunk, sub])\n\n        data['min_week'] = data['Weeks']\n        data.loc[data.WHERE == 'test', 'min_week'] = np.nan\n        data['min_week'] = data.groupby('Patient')['min_week'].transform('min')\n\n        base = data.loc[data.Weeks == data.min_week]\n        base = base[['Patient', 'FVC']].copy()\n        base.columns = ['Patient', 'min_FVC']\n        base['nb'] = 1\n        base['nb'] = base.groupby('Patient')['nb'].transform('cumsum')\n        base = base[base.nb == 1]\n        base.drop('nb', axis=1, inplace=True)\n\n        data = data.merge(base, on='Patient', how='left')\n        data['base_week'] = data['Weeks'] - data['min_week']\n        del base\n        gc.collect()\n        \n        COLS = ['Sex', 'SmokingStatus']\n        self.FE = []\n        for col in COLS:\n            for mod in data[col].unique():\n                self.FE.append(mod)\n                data[mod] = (data[col] == mod).astype(int)\n\n        data['age'] = (data['Age'] - data['Age'].min()) / \\\n                      (data['Age'].max() - data['Age'].min())\n        data['BASE'] = (data['min_FVC'] - data['min_FVC'].min()) / \\\n                       (data['min_FVC'].max() - data['min_FVC'].min())\n        data['week'] = (data['base_week'] - data['base_week'].min()) / \\\n                       (data['base_week'].max() - data['base_week'].min())\n        data['percent'] = (data['Percent'] - data['Percent'].min()) / \\\n                          (data['Percent'].max() - data['Percent'].min())\n        self.FE += ['age', 'percent', 'week', 'BASE']\n\n        self.raw = data.loc[data.WHERE == mode].reset_index()\n#         print(len(data))\n        del data\n\n    def __len__(self):\n        return len(self.raw)\n\n    def __getitem__(self, idx):\n        if torch.is_tensor(idx):\n            idx = idx.tolist()\n\n        patient_id = self.raw['Patient'].iloc[idx]\n        patient_path = os.path.join(self.ctscans_dir,patient_id)\n        if self.cache_dir is None:\n            patient_path = os.path.join(self.ctscans_dir,patient_id)\n            image, slices = self.load_scan(patient_path)\n            \n\n            image,metadata=self.resample(image,slices)\n           \n        else:\n            file_path=os.path.join(self.cache_dir,f'{patient_id}.pt')\n            try:\n                image = torch.load(file_path)\n            except:\n                image=torch.load(\"/kaggle/input/osic-preprocrsseddata/ID00078637202199415319443.pt\")\n            meta=os.listdir(patient_path)\n            meta0=meta[0]\n#             \n            metadata = pydicom.read_file(os.path.join(patient_path,meta0))\n           \n        sample = {\n            'features': self.raw[self.FE].iloc[idx].values,\n            'image': image,\n            'metadata': metadata,\n            'target': self.raw['FVC'].iloc[idx]\n        }\n        \n        if self.transform:\n            sample = self.transform(sample)\n            \n        return sample\n    \n    def parallel_save(self,f,path,bar):\n        sample=self[f]\n        patient_id = sample['metadata'].PatientID\n        sample['metadata'].save_as(os.path.join(cache_dir,f'{patient_id}.dcm'))\n      \n    \n    def cache(self, cache_dir):\n        Path(cache_dir).mkdir(exist_ok=True, parents=True)\n\n        # Cache raw features table\n        self.raw.to_csv(os.path.join(cache_dir,f'tabular_{self.mode}.csv'), index=False)\n\n        # Cache features list\n        with open(os.path.join(cache_dir,'features_list.pkl'), \"wb\") as fp:\n            pickle.dump(self.FE, fp)\n\n        # Cache images and metadata\n        self.raw['index'] = self.raw.index\n        idx_unique = self.raw.groupby('Patient').first()['index'].values\n        bar = tqdm(idx_unique.tolist())\n        for idx in bar:\n            sample = self[idx]\n            patient_id = sample['metadata'].PatientID\n\n\n            if sample['metadata'].TotalSlices>=1000 and self.mode==\"test\":\n                im=torch.load(\"/kaggle/input/osic-preprocrsseddata/ID00078637202199415319443.pt\")\n                torch.save(im, Path(cache_dir)/f'{patient_id}.pt')\n            else:  \n                torch.save(sample['image'], os.path.join(cache_dir,f'{patient_id}.pt'))\n#             sample['metadata'].save_as(os.path.join(cache_dir,f'{patient_id}.dcm'))\n            \n    @staticmethod\n    def load_scan(path):\n        \n#        \n        slices = [pydicom.dcmread(os.path.join(path,p)) for p in os.listdir(path)]\n#             slices = [pydicom.dcmread(dcm_path + \"/\" + file) for file in listdir(dcm_path)]\n#         print(slices[0].PatientID)\n#        print(\"load_scan\")\n#         if slices[0].PatientID==\"ID00132637202222178761324\":\n#             slice_thickness=0.625\n        \n#         elif slices[0].PatientID==\"ID00128637202219474716089\":\n#             slice_thickness=5.0\n            \n#         elif slices[0].PatientID==\"ID00173637202238329754031\":\n#             slice_thickness=1.0\n            \n#         elif (slices[0].PatientID==\"ID00052637202186188008618\") or (slices[0].PatientID==\"ID00011637202177653955184\"):\n#             return slices[0],slices\n            \n        \n#         else:\n           \n        try:\n            slices.sort(key = lambda x: float(x.InstanceNumber))\n#             slice_thickness=np.abs(slices[0].SpacingBetweenSlices)\n#             slices.sort(key=lambda x: float(x.ImagePositionPatient[2]))\n\n        except AttributeError:\n            warnings.warn(f'Patient {slices[0].PatientID} CT scan does not '\n                      f'have \"ImagePositionPatient\". Assuming filenames '\n                      f'in the right scan order.')\n#             try:'ImagePositionPatient' in slices[0].dir():\n#             try:\n#             slices.sort(key=lambda x: float(x.ImagePositionPatient[2]))\n#                 slice_thickness = np.abs(slices[0].ImagePositionPatient[2] - slices[1].ImagePositionPatient[2])\n#             except:\n#                 slice_thickness = np.abs(slices[0].SliceLocation - slices[1].SliceLocation)\n        arr=[]\n        for s in slices:\n            if s.Rows!=s.Columns:\n                s_data=s.pixel_array\n                s_cropped = s_data[~np.all(s_data == 0, axis=1)]\n                s_cropped = s_cropped[:, ~np.all(s_cropped == 0, axis=0)]\n                new_pix_array=s_cropped\n                s.PixelData = new_pix_array.tostring()\n                (s.Rows,s.Columns)=new_pix_array.shape\n\n            arr.append(s.pixel_array)\n#             s.SliceThickness = slice_thickness\n            \n        \n        \n        \n        image=np.stack(arr)\n        image=image.astype(float)\n        \n#         image = np.stack([s.pixel_array.astype(float) for s in slices])\n        return image, slices\n    \n    @staticmethod\n    def resample(image, scan,new_spacing=[1,1,1]):\n#         print(\"inresample\")\n#         print(scan[0].PatientID)\n      # print(type(scan))\n#         print(scan[0].SliceThickness)\n        \n        \n#         spacing=np.array([scan[0].SliceThickness, scan[0].PixelSpacing[0], scan[0].PixelSpacing[1]], dtype=np.float32)\n#         resize_factor = spacing / new_spacing\n#         new_real_shape = image.shape * resize_factor\n#         new_shape = np.round(new_real_shape)\n#         real_resize_factor = new_shape / image.shape\n#         new_spacing = spacing / real_resize_factor   \n# #         print(\"before zoom resizr\") \n#         image = scipy.ndimage.interpolation.zoom(image, real_resize_factor, mode='nearest')\n#         print(\"after zoom resie\")\n        metadata=scan[0]\n    \n        metadata.TotalSlices=len(scan[0])\n# #         print(metadata)\n# #         print(type(metadata))\n#         print(metadata.TotalSlices)\n        return image, scan[0]\n            \n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Preprocessing**"},{"metadata":{"trusted":true},"cell_type":"code","source":"class CropBoundingBox:\n    @staticmethod\n    def bounding_box(img3d: np.array):\n        mid_img = img3d[int(img3d.shape[0] / 2)]\n        same_first_row = (mid_img[0, :] == mid_img[0, 0]).all()\n        same_first_col = (mid_img[:, 0] == mid_img[0, 0]).all()\n        if same_first_col and same_first_row:\n            return True\n        else:\n            return False\n\n    def __call__(self, sample):\n        features,image,data,target = sample['features'],sample['image'], sample['metadata'],sample['target']\n        \n        if not self.bounding_box(image):\n            return sample\n\n        mid_img = image[int(image.shape[0] / 2)]\n        r_min, r_max = None, None\n        c_min, c_max = None, None\n        for row in range(mid_img.shape[0]):\n            if not (mid_img[row, :] == mid_img[0, 0]).all() and r_min is None:\n                r_min = row\n            if (mid_img[row, :] == mid_img[0, 0]).all() and r_max is None \\\n                    and r_min is not None:\n                r_max = row\n                break\n\n        for col in range(mid_img.shape[1]):\n            if not (mid_img[:, col] == mid_img[0, 0]).all() and c_min is None:\n                c_min = col\n            if (mid_img[:, col] == mid_img[0, 0]).all() and c_max is None \\\n                    and c_min is not None:\n                c_max = col\n                break\n\n        image = image[:, r_min:r_max, c_min:c_max]\n        return {'features':features,'image': image, 'metadata': data,'target':target}","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3.2.2. convert_to_hu.py\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"class ConvertToHU:\n    def __call__(self, sample):\n        features,image,data,target = sample['features'],sample['image'], sample['metadata'],sample['target']\n\n        img_type = data.ImageType\n        is_hu = img_type[0] == 'ORIGINAL' and not (img_type[2] == 'LOCALIZER')\n        # if not is_hu:\n        #     warnings.warn(f'Patient {data.PatientID} CT Scan not cannot be'\n        #                   f'converted to Hounsfield Units (HU).')\n\n        intercept = data.RescaleIntercept\n        slope = data.RescaleSlope\n        image = (image * slope + intercept).astype(np.int16)\n        return {'features':features,'image': image, 'metadata': data,'target':target}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Resize:\n    def __init__(self, output_size):\n        assert isinstance(output_size, tuple)\n        self.output_size = output_size\n\n    def __call__(self, sample):\n        features,image,data,target = sample['features'],sample['image'], sample['metadata'],sample['target']\n        resize_factor = np.array(self.output_size) / np.array(image.shape)\n        image = zoom(image, resize_factor, mode='nearest')\n        return {'features':features,'image': image, 'metadata': data,'target':target}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Clip:\n    def __init__(self, bounds=(-1000, 500)):\n        self.min = min(bounds)\n        self.max = max(bounds)\n\n    def __call__(self, sample):\n        features,image,data,target = sample['features'],sample['image'], sample['metadata'],sample['target']\n        image[image < self.min] = self.min\n        image[image > self.max] = self.max\n        return {'features':features,'image': image, 'metadata': data,'target':target}","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Segmentation"},{"metadata":{"trusted":true},"cell_type":"code","source":"class MaskWatershed:\n    def __init__(self, min_hu, iterations, show_tqdm):\n        self.min_hu = min_hu\n        self.iterations = iterations\n        self.show_tqdm = show_tqdm\n\n    def __call__(self, sample):\n        features,image,data,target = sample['features'],sample['image'], sample['metadata'],sample['target']\n\n        stack = []\n        if self.show_tqdm:\n            bar = trange(image.shape[0])\n            bar.set_description(f'Masking CT scan {data.PatientID}')\n        else:\n            bar = range(image.shape[0])\n        for slice_idx in bar:\n            sliced = image[slice_idx]\n            stack.append(self.seperate_lungs(sliced, self.min_hu,\n                                             self.iterations))\n\n        return {\n            'features':features,\n            'image': np.stack(stack),\n            'metadata': sample['metadata'],\n            'target':target\n        }\n\n    @staticmethod\n    def seperate_lungs(image, min_hu, iterations):\n        h, w = image.shape[0], image.shape[1]\n\n        marker_internal, marker_external, marker_watershed = MaskWatershed.generate_markers(image)\n\n        # Sobel-Gradient\n        sobel_filtered_dx = ndimage.sobel(image, 1)\n        sobel_filtered_dy = ndimage.sobel(image, 0)\n        sobel_gradient = np.hypot(sobel_filtered_dx, sobel_filtered_dy)\n        sobel_gradient *= 255.0 / np.max(sobel_gradient)\n\n        watershed = morphology.watershed(sobel_gradient, marker_watershed)\n\n        outline = ndimage.morphological_gradient(watershed, size=(3,3))\n        outline = outline.astype(bool)\n\n        # Structuring element used for the filter\n        blackhat_struct = [[0, 0, 1, 1, 1, 0, 0],\n                           [0, 1, 1, 1, 1, 1, 0],\n                           [1, 1, 1, 1, 1, 1, 1],\n                           [1, 1, 1, 1, 1, 1, 1],\n                           [1, 1, 1, 1, 1, 1, 1],\n                           [0, 1, 1, 1, 1, 1, 0],\n                           [0, 0, 1, 1, 1, 0, 0]]\n\n        blackhat_struct = ndimage.iterate_structure(blackhat_struct, iterations)\n\n        # Perform Black Top-hat filter\n        outline += ndimage.black_tophat(outline, structure=blackhat_struct)\n\n        lungfilter = np.bitwise_or(marker_internal, outline)\n        lungfilter = ndimage.morphology.binary_closing(lungfilter, structure=np.ones((5,5)), iterations=3)\n\n        segmented = np.where(lungfilter == 1, image, min_hu * np.ones((h, w)))\n\n        return segmented  #, lungfilter, outline, watershed, sobel_gradient\n\n    @staticmethod\n    def generate_markers(image, threshold=-400):\n        h, w = image.shape[0], image.shape[1]\n\n        marker_internal = image < threshold\n        marker_internal = segmentation.clear_border(marker_internal)\n        marker_internal_labels = measure.label(marker_internal)\n\n        areas = [r.area for r in measure.regionprops(marker_internal_labels)]\n        areas.sort()\n\n        if len(areas) > 2:\n            for region in measure.regionprops(marker_internal_labels):\n                if region.area < areas[-2]:\n                    for coordinates in region.coords:\n                        marker_internal_labels[coordinates[0], coordinates[1]] = 0\n\n        marker_internal = marker_internal_labels > 0\n\n        # Creation of the External Marker\n        external_a = ndimage.binary_dilation(marker_internal, iterations=10)\n        external_b = ndimage.binary_dilation(marker_internal, iterations=55)\n        marker_external = external_b ^ external_a\n\n        # Creation of the Watershed Marker\n        marker_watershed = np.zeros((h, w), dtype=np.int)\n        marker_watershed += marker_internal * 255\n        marker_watershed += marker_external * 128\n\n        return marker_internal, marker_external, marker_watershed","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Normalize:\n    def __init__(self, bounds=(-1000, 500)):\n        self.min = min(bounds)\n        self.max = max(bounds)\n\n    def __call__(self, sample):\n        features,image,data,target = sample['features'],sample['image'], sample['metadata'],sample['target']\n        image = image.astype(np.float)\n        image = (image - self.min) / (self.max - self.min)\n        return {'features':features,'image': image, 'metadata': data,'target':target}\n    \n\nclass ToTensor:\n    def __init__(self, add_channel=True):\n        self.add_channel = add_channel\n\n    def __call__(self, sample):\n        features,image,data,target = sample['features'],sample['image'], sample['metadata'],sample['target']\n        if self.add_channel:\n            image = np.expand_dims(image, axis=0)\n\n        return {'features':features,'image': torch.from_numpy(image), 'metadata': data,'target':target}\n    \nclass ZeroCenter:\n    def __init__(self, pre_calculated_mean):\n        self.pre_calculated_mean = pre_calculated_mean\n\n    def __call__(self, sample):\n        return {\n            'features': sample['features'],\n            'image': sample['image'] - self.pre_calculated_mean,\n            'metadata': sample['metadata'],\n            'target': sample['target']\n        }","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def show(list_imgs, cmap=cm.bone):\n    list_slices = []\n    for img3d in list_imgs:\n        slc = int(img3d.shape[0] / 2)\n        img = img3d[slc]\n        list_slices.append(img)\n    \n    fig, axs = plt.subplots(1, 5, figsize=(15, 7))\n    for i, img in enumerate(list_slices):\n        axs[i].imshow(img, cmap=cmap)\n        axs[i].axis('off')\n        \n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = ClinicalDataset(\n    root_dir=root_dir,\n    ctscans_dir=os.path.join(root_dir,'test'),\n    mode='test',\n    transform=transforms.Compose([\n        CropBoundingBox(),\n        ConvertToHU(),\n        Resize((40, 256, 256)),\n        Clip(bounds=clip_bounds),\n        MaskWatershed(\n            min_hu=min(clip_bounds),\n            iterations=watershed_iterations,\n            show_tqdm=False),\n        Normalize(bounds=clip_bounds),\n        ToTensor(),\n         ZeroCenter(pre_calculated_mean=pre_calculated_mean)\n    ]))\n\ndata.cache(\"/kaggle/working/test_cache\")                         ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef check_submit():\n    tr = pd.read_csv(Path(root_dir)/\"train.csv\")\n    tr.drop_duplicates(keep=False, inplace=True, subset=['Patient', 'Weeks'])\n    chunk = pd.read_csv(Path(root_dir)/\"test.csv\")\n\n    sub = pd.read_csv(Path(root_dir)/\"sample_submission.csv\")\n    sub['Patient'] = sub['Patient_Week'].apply(lambda x: x.split('_')[0])\n    sub['Weeks'] = sub['Patient_Week'].apply(lambda x: int(x.split('_')[-1]))\n    sub = sub[['Patient', 'Weeks', 'Confidence', 'Patient_Week']]\n    sub = sub.merge(chunk.drop('Weeks', axis=1), on=\"Patient\")\n\n    tr['WHERE'] = 'train'\n    chunk['WHERE'] = 'val'\n    sub['WHERE'] = 'test'\n    data = tr.append([chunk, sub])\n\n    data['min_week'] = data['Weeks']\n    data.loc[data.WHERE == 'test', 'min_week'] = np.nan\n    data['min_week'] = data.groupby('Patient')['min_week'].transform('min')\n\n    base = data.loc[data.Weeks == data.min_week]\n    base = base[['Patient', 'FVC']].copy()\n    base.columns = ['Patient', 'min_FVC']\n    base['nb'] = 1\n    base['nb'] = base.groupby('Patient')['nb'].transform('cumsum')\n    base = base[base.nb == 1]\n    base.drop('nb', axis=1, inplace=True)\n\n    data = data.merge(base, on='Patient', how='left')\n    data['base_week'] = data['Weeks'] - data['min_week']\n    del base\n\n    COLS = ['Sex', 'SmokingStatus']\n    FE = []\n    for col in COLS:\n        for mod in data[col].unique():\n            FE.append(mod)\n            data[mod] = (data[col] == mod).astype(int)\n\n    data['age'] = (data['Age'] - data['Age'].min()) / \\\n                  (data['Age'].max() - data['Age'].min())\n    data['BASE'] = (data['min_FVC'] - data['min_FVC'].min()) / \\\n                   (data['min_FVC'].max() - data['min_FVC'].min())\n    data['week'] = (data['base_week'] - data['base_week'].min()) / \\\n                   (data['base_week'].max() - data['base_week'].min())\n    data['percent'] = (data['Percent'] - data['Percent'].min()) / \\\n                      (data['Percent'].max() - data['Percent'].min())\n    FE += ['age', 'percent', 'week', 'BASE']\n    raw = data.loc[data.WHERE == 'test'].reset_index()\n    del data\n    return raw\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dm = ClinicalDataset(\n    root_dir=root_dir,\n    ctscans_dir=os.path.join(root_dir,'test'),\n    mode='test',\n    transform=transforms.Compose([\n        CropBoundingBox(),\n        ConvertToHU(),\n        Resize((40, 256, 256)),\n        Clip(bounds=clip_bounds),\n        MaskWatershed(\n            min_hu=min(clip_bounds),\n            iterations=watershed_iterations,\n            show_tqdm=False),\n        Normalize(bounds=clip_bounds),\n        ToTensor(),\n         ZeroCenter(pre_calculated_mean=pre_calculated_mean)\n    ]))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"QuantModel"},{"metadata":{"trusted":true},"cell_type":"code","source":"class QuantModel(nn.Module):\n    def __init__(self, in_tabular_features=9, in_ctscan_features=10,\n                 out_quantiles=3):\n        super(QuantModel, self).__init__()\n        # This line is new. We need to know a priori the number\n        # of latent features to properly flatten the tensor\n        self.in_ctscan_features = in_ctscan_features\n\n        self.fc1 = nn.Linear(in_tabular_features, 512)\n        self.fc=nn.Linear(512,256)\n        self.fc2 = nn.Linear(in_ctscan_features, 512)\n        self.fc3 = nn.Linear(512, 256)\n        self.fcl=nn.Linear(256,128)\n        self.fc4 = nn.Linear(128, out_quantiles)\n#         self.dropout = nn.Dropout(p=0.5) \n    def forward(self, x1, x2):\n        # Now the quant model has 2 inputs: x1 (the tabular features)\n        # and x2 (the pre-computed latent features)\n#         print(x1.shape)\n        x1 = F.relu(self.fc1(x1))\n#         x1=self.dropout(x1)\n        x1=F.relu(self.fc(x1))\n#         print(\"x1\")\n#         print(x1.shape)\n#         print(\"x2\")\n#         print(x2.shape)\n        # Flattens the latent features and concatenate with tabular features\n#         x2 = x2.view(-1, self.in_ctscan_features)\n#         print(x2.shape)\n        x2 = F.relu(self.fc2(x2))\n        x2=F.relu(self.fc(x2))\n#         print(x2.shape)\n        x = torch.cat([x1, x2], dim=1)\n#         x=self.dropout(x)\n        x = F.relu(self.fc3(x))\n        x=F.relu(self.fcl(x))\n        x = self.fc4(x)\n        return x","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Quant loss"},{"metadata":{"trusted":true},"cell_type":"code","source":"def quantile_loss(preds, target, quantiles):\n    assert not target.requires_grad\n    assert preds.size(0) == target.size(0)\n    losses = []                                              \n    for i, q in enumerate(quantiles):                                                                \n        errors = target - preds[:, i]\n        losses.append(torch.max((q - 1) * errors, q * errors).unsqueeze(1))   \n    loss = torch.mean(torch.sum(torch.cat(losses, dim=1), dim=1))                                                \n    return loss","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"AutoEncoder"},{"metadata":{"trusted":true},"cell_type":"code","source":"class AutoEncoder(nn.Module):\n    def __init__(self, latent_features=latent_features):\n        super(AutoEncoder, self).__init__()\n        # Encoder\n        self.conv1 = nn.Conv3d(1, 16, 3)\n        self.conv2 = nn.Conv3d(16, 32, 3)\n        self.conv3 = nn.Conv3d(32, 96, 2)\n        self.conv4 = nn.Conv3d(96, 1, 1)\n        self.pool1 = nn.MaxPool3d(kernel_size=2, stride=2, return_indices=True)\n        self.pool2 = nn.MaxPool3d(kernel_size=3, stride=3, return_indices=True)\n        self.pool3 = nn.MaxPool3d(kernel_size=2, stride=2, return_indices=True)\n        self.pool4 = nn.MaxPool3d(kernel_size=2, stride=2, return_indices=True)\n        self.fc1 = nn.Linear(10 * 10, latent_features)\n        # Decoder\n        self.fc2 = nn.Linear(latent_features, 10 * 10)\n        self.deconv0 = nn.ConvTranspose3d(1, 96, 1)\n        self.deconv1 = nn.ConvTranspose3d(96, 32, 2)\n        self.deconv2 = nn.ConvTranspose3d(32, 16, 3)\n        self.deconv3 = nn.ConvTranspose3d(16, 1, 3)\n        self.unpool0 = nn.MaxUnpool3d(kernel_size=2, stride=2)\n        self.unpool1 = nn.MaxUnpool3d(kernel_size=2, stride=2)\n        self.unpool2 = nn.MaxUnpool3d(kernel_size=3, stride=3)\n        self.unpool3 = nn.MaxUnpool3d(kernel_size=2, stride=2)\n\n    def encode(self, x, return_partials=True):\n        # Encoder\n        x = self.conv1(x)\n        up3out_shape = x.shape\n        x, i1 = self.pool1(x)\n\n        x = self.conv2(x)\n        up2out_shape = x.shape\n        x, i2 = self.pool2(x)\n\n        x = self.conv3(x)\n        up1out_shape = x.shape\n        x, i3 = self.pool3(x)\n\n        x = self.conv4(x)\n        up0out_shape = x.shape\n        x, i4 = self.pool4(x)\n\n        x = x.view(-1, 10 * 10)\n        x = F.relu(self.fc1(x))\n\n        if return_partials:\n            return x, up3out_shape, i1, up2out_shape, i2, up1out_shape, i3, \\\n                   up0out_shape, i4\n\n        else:\n            return x\n\n    def forward(self, x):\n        x, up3out_shape, i1, up2out_shape, i2, \\\n        up1out_shape, i3, up0out_shape, i4 = self.encode(x)\n\n        # Decoder\n        x = F.relu(self.fc2(x))\n        x = x.view(-1, 1, 1, 10, 10)\n        x = self.unpool0(x, output_size=up0out_shape, indices=i4)\n        x = self.deconv0(x)\n        x = self.unpool1(x, output_size=up1out_shape, indices=i3)\n        x = self.deconv1(x)\n        x = self.unpool2(x, output_size=up2out_shape, indices=i2)\n        x = self.deconv2(x)\n        x = self.unpool3(x, output_size=up3out_shape, indices=i1)\n        x = self.deconv3(x)\n\n        return x","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Cache all pre-processed 3D CT Scans and pre-compute all latent features"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Helper function that generates all latent features\nclass GenerateLatentFeatures:\n    def __init__(self, autoencoder,cache_dir, latent_dir,mode):\n        self.autoencoder = autoencoder\n        self.latent_dir =latent_dir\n        self.cache_dir = cache_dir\n        self.mode=mode\n\n    def __call__(self, sample):\n        patient_id = sample['metadata'].PatientID\n        cached_latent_file = os.path.join(self.latent_dir,f'{patient_id}_lat.pt')\n        if os.path.isfile(cached_latent_file):\n            latent_features = torch.load(cached_latent_file)\n        else:\n            with torch.no_grad():\n                img=sample['image'].to(device)\n                img = img.float().unsqueeze(0)\n                latent_features = self.autoencoder.encode(\n                    img, return_partials=False).squeeze(0)\n            torch.save(latent_features, cached_latent_file)\n            if self.mode=='test':\n#                 print(os.path.join(self.cache,f'{patient_id}.pt'))\n#                 pathlib.Path.unlink(self.cache_dir/f'{patient_id}.pt')\n                try:\n                    os.remove(os.path.join(self.cache_dir,f'{patient_id}.pt'))\n                except AttributeError:\n                    warnings.warn(f'Patient {slices[0].PatientID} CT scan does not '\n                      f'have \"ImagePositionPatient\". Assuming filenames '\n                      f'in the right scan order.')\n\n        return {\n            'tabular_features': sample['features'],\n            'latent_features': latent_features,\n            'target': sample['target']\n        }","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"autoencoder = AutoEncoder()\nautoencoder.load_state_dict(torch.load(\n    pretrained_ae_weigths,\n    map_location=torch.device('cuda')\n))\n# print(pretrained_ae_weigths.shape)\nautoencoder.to(device)\nautoencoder.eval()\n\ndata = ClinicalDataset(\n    root_dir=root_dir,\n    ctscans_dir=os.path.join(root_dir,'train'),\n    cache_dir=cache_dir,\n    mode='train',\n    transform=GenerateLatentFeatures(autoencoder,cache_dir, latent_dir,'train')\n)\nfor i in trange(len(data)):\n    sample = data[i]\n#     print(sample['latent_features'].shape)\n#     assert sample['latent_features'].shape == (96, 2, 20, 20)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* 1. Overfit a small batch before moving forward"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataloader = DataLoader(data, batch_size=batch_size,\n                        shuffle=True, num_workers=0)\n# dataloader=dataloader.cuda()num_workers to 0 and pin_memory to False.\nbatch = next(iter(dataloader))\n\nmodel = QuantModel().to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\nbar = trange(50)\nfor epoch in bar:\n    inputs1 = batch['tabular_features'].float().to(device)\n    inputs2 = batch['latent_features'].float().to(device)\n    targets = batch['target'].to(device)\n\n    optimizer.zero_grad()\n    preds = model(inputs1, inputs2)\n    loss = quantile_loss(preds, targets, quantiles)\n    loss.backward()\n\n    optimizer.step()\n    \n\n    bar.set_postfix(loss=f'{loss.item():0.1f}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Helper generator that group splits\ndef group_split(dataset, groups, test_size=0.2):\n    gss = GroupShuffleSplit(n_splits=1, test_size=test_size)\n    idx = list(gss.split(dataset.raw, dataset.raw, groups))\n    train = Subset(dataset, idx[0][0])\n    val = Subset(dataset, idx[0][1])\n    return train, val\n\ndef group_kfold(dataset,n_splits):\n    gkf = GroupKFold(n_splits=n_splits)\n    groups = dataset.raw['Patient']\n    for train_idx, val_idx in gkf.split(dataset.raw, dataset.raw, groups):\n        train = Subset(dataset, train_idx)\n        val = Subset(dataset, val_idx)\n        yield train, val\n\n\n# Helper function with competition metric\ndef metric(preds, targets):\n#     print(preds.shape)\n#     print(targets.shape)\n    \n    sigma = preds[:, 2] - preds[:, 0]\n    sigma[sigma < 70] = 70\n    delta = (preds[:, 1] - targets).abs()\n    delta[delta > 1000] = 1000\n#     print(\"end\")\n    return -np.sqrt(2) * delta / sigma - torch.log(np.sqrt(2) * sigma)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **lr_scheduler method and callbacks**"},{"metadata":{"trusted":true},"cell_type":"code","source":"trainset, valset = group_split(data, data.raw['Patient'], test_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" dataloaders = {\n        'train': DataLoader(trainset, batch_size=batch_size,\n                            shuffle=True, num_workers=0),\n        'val': DataLoader(valset, batch_size=batch_size,\n                          shuffle=False, num_workers=0)\n    }","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#export\nclass DataBunch():\n    def __init__(self, train_dl, valid_dl):\n        self.train_dl,self.valid_dl = train_dl,valid_dl\n        \n    @property\n    def train_ds(self): return self.train_dl.dataset\n        \n    @property\n    def valid_ds(self): return self.valid_dl.dataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = DataBunch(dataloaders['train'],dataloaders['val'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_model(data):\n    model = QuantModel().to(device)\n    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n    return model, optimizer\n\nclass Learner():\n    def __init__(self, model, opt, data):\n        self.model,self.opt,self.data = model,opt,data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\n\n_camel_re1 = re.compile('(.)([A-Z][a-z]+)')\n_camel_re2 = re.compile('([a-z0-9])([A-Z])')\ndef camel2snake(name):\n    s1 = re.sub(_camel_re1, r'\\1_\\2', name)\n    return re.sub(_camel_re2, r'\\1_\\2', s1).lower()\n\nclass Callback():\n    _order=0\n    def set_runner(self,run):self.run=run\n\n    def __getattr__(self,k):return getattr(self.run, k)\n\n    @property\n    def name(self):\n        name = re.sub(r'Callback$', '', self.__class__.__name__)\n        return camel2snake(name or 'callback')\n    \n    def __call__(self, cb_name):\n        f = getattr(self, cb_name, None)\n        if f and f(): return True\n        return False\n\n\nclass CancelTrainException(Exception): pass\nclass CancelEpochException(Exception): pass\nclass CancelBatchException(Exception): pass","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class TrainEvalCallback(Callback):\n    def begin_fit(self):\n        self.run.n_epochs=0.\n        self.run.n_iter=0\n    \n    def after_batch(self):\n        if not self.in_train: return\n        self.run.n_epochs += 1./self.iters\n        self.run.n_iter   += 1\n        \n    def begin_epoch(self):\n        self.run.n_epochs=self.epoch\n        self.model.train()\n        self.run.in_train=True\n\n    def begin_validate(self):\n        self.model.eval()\n        self.run.in_train=False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Set global tracking variables\nepoch_loss = {'train': np.inf, 'val': np.inf}\nepoch_metric = {'train': -np.inf, 'val': -np.inf}\nbest_loss = np.inf\nbest_model_wts = None\n\n\nmodel_dir = '/kaggle/working/'\nPath(model_dir).mkdir(parents=True, exist_ok=True)\nnow = datetime.now()\nfname = f'{model_name}-{now.year}{now.month:02d}{now.day:02d}.pth'\nmodel_file = Path(model_dir) / fname","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Runner():\n    def __init__(self, cbs=None, cb_funcs=None):\n        self.in_train = False\n        cbs = listify(cbs)\n        for cbf in listify(cb_funcs):\n            cb = cbf()\n            setattr(self, cb.name, cb)\n            cbs.append(cb)\n        self.stop,self.cbs = False,[TrainEvalCallback()]+cbs\n        self.best_loss = np.inf\n        self.val_loss = np.inf\n        self.best_model_wts = None\n#         self.bar=torch.tensor(0.)\n\n    @property\n    def opt(self):       return self.learn.opt\n    @property\n    def model(self):     return self.learn.model\n#     @property\n#     def loss_func(self): return self.learn.loss_func\n    @property\n    def data(self):      return self.learn.data\n    \n    @property\n    def best_model_weights(self):\n        return self.best_model_wts\n    \n    def one_batch(self, inputs1, inputs2,targets):\n        try:\n            self.inputs1,self.inputs1,self.targets = inputs1,inputs2,targets\n            self.loss =torch.tensor(0.)\n            self('begin_batch')\n            self.preds = self.model(inputs1, inputs2)\n    #         model(inputs1, inputs2)\n            self('after_pred')\n            self.loss = quantile_loss(self.preds, self.targets, quantiles)\n            self('after_loss')\n            if not self.in_train: return\n            self.loss.backward()\n            self('after_backward')\n            self.opt.step()\n            self('after_step')\n            self.opt.zero_grad()\n        \n        except CancelBatchException: self('after_cancel_batch')\n            \n        finally: self('after_batch')\n\n\n    def all_batches(self, dl):\n        try:\n            self.iters = len(dl)\n            self.bar = tqdm(dl)\n            self.mode=None\n            for batch in self.bar:\n                if self.stop: break\n                if self.in_train: mode='train'\n                else: mode='valid'\n                self.bar.set_description(f'Epoch {self.epoch} {mode}'.ljust(20))    \n                inputs1 = batch['tabular_features'].float().to(device)\n                inputs2 = batch['latent_features'].float().to(device)\n                targets = batch['target'].to(device)\n            \n                self.one_batch(inputs1,inputs2,targets)\n#             self('after_batch')\n#         self.stop=False\n        \n        except CancelEpochException: self('after_cancel_epoch')\n\n    def fit(self, epochs, learn):\n        self.epochs,self.learn= epochs,learn\n\n\n        try:\n            for cb in self.cbs: cb.set_runner(self)\n            self('begin_fit')\n            for epoch in range(epochs):\n                self.epoch = epoch\n                if not self('begin_epoch'): self.all_batches(self.data.train_dl)\n\n                with torch.no_grad(): \n                    if not self('begin_validate'): self.all_batches(self.data.valid_dl)\n                self('after_epoch')\n        \n        except CancelTrainException: self('after_cancel_train')\n            \n        finally:\n            self('after_fit')\n            self.learn = None\n\n    def __call__(self, cb_name):\n        res = False\n        for cb in sorted(self.cbs, key=lambda x: x._order): res = cb(cb_name) or res\n        return res","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class AvgStats():\n    \n    def __init__(self, metrics, in_train): \n        self.metrics,self.in_train = listify(metrics),in_train\n\n    \n    def reset(self):\n        self.tot_loss,self.count = 0.,0\n        self.tot_mets = [0.] * len(self.metrics)\n        \n    @property\n    def all_stats(self): return [self.tot_loss] + self.tot_mets\n    @property\n    def avg_stats(self):\n#         print(self.all_stats)\n        return [o/self.count for o in self.all_stats]\n    @property\n    def best_weights(self):\n        return self.best_model_wts \n        \n    def saved_weights(self,run):\n#         if not self.count: return \"\"\n        if self.in_train==False:\n            run.val_loss=self.avg_stats[0]\n        if (self.in_train==False) and (self.avg_stats[0] < run.best_loss):\n            run.best_loss = self.avg_stats[0]\n            run.best_model_wts = copy.deepcopy(run.model.state_dict())\n            torch.save(run.best_model_wts, model_file)       \n            \n#         return f\"{'train' if self.in_train else 'valid'}: loss:{self.avg_stats[0]:0.1f}, metric:{self.avg_stats[1]:0.4f}\"\n\n    def accumulate(self, run):\n        self.batch_mat=[0.]\n        bn = run.inputs1.size(0)\n#         bn = run.xb.shape[0]\n        \n#         self.running_loss += loss.item() * inputs1.size(0)\n        self.tot_loss += run.loss.item() * bn\n#         self.running_metric+=metric(self.preds, self.targets).sum()\n#         running_loss += loss.item() * inputs1.size(0)\n#         running_metric += metric(preds, targets).sum()\n        self.count += bn\n#         print(self.metrics)\n        for i,m in enumerate(self.metrics):\n            k=m(run.preds, run.targets).sum()\n            self.tot_mets[i] += k\n\n\n        run.bar.set_postfix(loss=f'{self.tot_loss / self.count :0.1f}',\n                            metric=f'{self.tot_mets[0] / self.count :0.4f}')\n\nclass AvgStatsCallback(Callback):\n    _order=1\n    def __init__(self,metrics):\n        self.train_stats,self.valid_stats=AvgStats(metrics,True),AvgStats(metrics,False)\n  \n    def begin_epoch(self):\n        self.train_stats.reset()\n        self.valid_stats.reset()\n  \n    def after_loss(self):\n        stats=self.train_stats if self.in_train else self.valid_stats\n        with torch.no_grad():\n            stats.accumulate(self.run)\n  \n    def after_epoch(self):\n        self.valid_stats.saved_weights(self.run)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Recorder(Callback):\n    def begin_fit(self):\n        self.lrs,self.losses=[],[]\n  \n    def after_batch(self):\n        if not self.in_train:return\n        self.lrs.append(self.opt.param_groups[-1]['lr'])\n        self.losses.append(self.loss.detach().cpu())\n  \n    def plot_lr(self):\n        plt.plot(self.lrs)\n  \n    def plot_losses(self):\n        plt.plot(self.losses)\n\nclass ParamScheduler(Callback):\n    _order=1\n    def __init__(self,pname,sched_func):\n        self.pname,self.sched_func=pname,sched_func\n  \n    def set_param(self):\n        for pg in self.opt.param_groups:\n            pg[self.pname]=self.sched_func(self.n_epochs/self.epochs)\n  \n    def begin_batch(self):\n        if self.in_train : self.set_param()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class EarlyStopping(Callback):\n    _order=2\n    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n    def __init__(self, patience=7, verbose=False, delta=0):\n        \"\"\"\n        Args:\n            patience (int): How long to wait after last time validation loss improved.\n                            Default: 7\n            verbose (bool): If True, prints a message for each validation loss improvement. \n                            Default: False\n            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n                            Default: 0\n            path (str): Path for the checkpoint to be saved to.\n                            Default: 'checkpoint.pt'\n        \"\"\"\n        self.patience = patience\n        self.verbose = verbose\n        self.counter = 0\n        self.best_score = None\n#         self.early_stop = False\n#         self.val_loss_min = np.Inf\n        self.delta = delta\n#         self.path = path\n\n\n    def after_epoch(self):\n        with torch.no_grad():\n            \n            score = -self.run.val_loss\n            if self.best_score is None:\n                print(\"k\")\n                self.best_score = score\n                self.save_checkpoint(self.run.val_loss, self.run.model)\n            elif score < self.best_score + self.delta:\n                self.counter += 1\n                \n                if self.counter >= self.patience:\n#                     self.early_stop = True\n                    raise CancelTrainException()\n            else:\n                self.best_score = score\n                self.save_checkpoint(self.run.val_loss, self.run.model)\n                self.counter = 0\n        \n\n    def save_checkpoint(self, val_loss, model):\n        '''Saves model when validation loss decrease.'''\n        if self.verbose:\n            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n        torch.save(model.state_dict(), model_file)\n        self.val_loss_min = val_loss","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from functools import partial","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#export\ndef annealer(f):\n    def _inner(start, end): return partial(f, start, end)\n    return _inner\n\n@annealer\ndef sched_lin(start, end, pos): return start + pos*(end-start)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"@annealer\ndef sched_cos(start, end, pos): return start + (1 + math.cos(math.pi*(1-pos))) * (end-start) / 2\n@annealer\ndef sched_no(start, end, pos):  return start\n@annealer\ndef sched_exp(start, end, pos): return start * (end/start) ** pos\n\ndef cos_1cycle_anneal(start, high, end):\n    return [sched_cos(start, high), sched_cos(high, end)]\n\ntorch.Tensor.ndim = property(lambda x: len(x.shape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def combine_scheds(pcts, scheds):\n    assert sum(pcts) == 1.\n    pcts = torch.tensor([0] + listify(pcts))\n    assert torch.all(pcts >= 0)\n    pcts = torch.cumsum(pcts, 0)\n    def _inner(pos):\n        idx = (pos >= pcts).nonzero().max()\n        if idx == 2: idx = 1\n        actual_pos = (pos-pcts[idx]) / (pcts[idx+1]-pcts[idx])\n        return scheds[idx](actual_pos)\n    return _inner","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from typing import *\n\ndef listify(o):\n    if o is None: return []\n    if isinstance(o, list): return o\n    if isinstance(o, str): return [o]\n    if isinstance(o, Iterable): return list(o)\n    return [o]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr_start   = 0.5e-03\nlr_max     = 3e-03\nlr_min     = 0.1e-03\nlr_ramp_percent =  0.3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sched = combine_scheds([0.4, 0.6], [sched_cos(lr_start, lr_max), sched_cos(lr_max, lr_min)]) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn = Learner(*get_model(data), data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# acc_cbf=partial(AvgStatsCallback,metric)\n# cbfs=[Recorder,\n#       partial(AvgStatsCallback,metric)]\ncbfs = [Recorder,\n        partial(AvgStatsCallback,metric),\n        partial(ParamScheduler, 'lr', sched),\n        partial(EarlyStopping,patience=80)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"run = Runner(cb_funcs=cbfs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import math","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"run.fit(20, learn)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"run.recorder.plot_lr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"run.recorder.plot_losses()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print(run.best_model_weights)\n# a=run.best_model_weights\n# # model = QuantModel().to(device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.load_state_dict(run.best_model_wts)\n# model.load_state_dict(\"/kaggle/working/cauchy-20201004.pth\")\n\n# print(f'Training complete! Time: {timedelta(seconds=time() - t0)}')\nmodels = [model]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"END OF new Approach"},{"metadata":{},"cell_type":"markdown","source":"# **Training**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Helper generator that group splits\n# def group_split(dataset, groups, test_size=0.2):\n#     gss = GroupShuffleSplit(n_splits=1, test_size=test_size)\n#     idx = list(gss.split(dataset.raw, dataset.raw, groups))\n#     train = Subset(dataset, idx[0][0])\n#     val = Subset(dataset, idx[0][1])\n#     return train, val\n\n# def group_kfold(dataset,n_splits):\n#     gkf = GroupKFold(n_splits=n_splits)\n#     groups = dataset.raw['Patient']\n#     for train_idx, val_idx in gkf.split(dataset.raw, dataset.raw, groups):\n#         train = Subset(dataset, train_idx)\n#         val = Subset(dataset, val_idx)\n#         yield train, val\n\n\n# # Helper function with competition metric\n# def metric(preds, targets):\n#     sigma = preds[:, 2] - preds[:, 0]\n#     sigma[sigma < 70] = 70\n#     delta = (preds[:, 1] - targets).abs()\n#     delta[delta > 1000] = 1000\n#     return -np.sqrt(2) * delta / sigma - torch.log(np.sqrt(2) * sigma)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Helper class that monitors training\n# class Monitor:\n#     def __init__(self, model, es_patience, experiment_name, tensorboard_dir,\n#                  num_epochs, dataset_sizes, model_file):\n\n#         self.model = model\n#         self.model_file = model_file\n#         self.es_patience = es_patience\n#         self.tensorboard_dir = tensorboard_dir\n#         self.dataset_sizes = dataset_sizes\n#         date_time = datetime.now().strftime(\"%Y%m%d-%H%M\")\n#         log_dir = tensorboard_dir / f'{experiment_name}-{date_time}'\n#         self.w = SummaryWriter(log_dir)\n\n#         self.bar = trange(num_epochs, desc=experiment_name)\n\n#         self.epoch_loss = {'train': np.inf, 'val': np.inf}\n#         self.epoch_metric = {'train': -np.inf, 'val': -np.inf}\n#         self.best_loss = np.inf\n#         self.best_model_wts = None\n\n#         self.e = {'train': 0, 'val': 0}  # epoch counter\n#         self.t = {'train': 0, 'val': 0}  # global time-step (never resets)\n#         self.running_loss = 0.0\n#         self.running_metric = 0.0\n#         self.es_counter = 0\n\n#     def reset_epoch(self):\n#         self.running_loss = 0.0\n#         self.running_metric = 0.0\n\n#     def step(self, loss, inputs1,inputs2, preds, targets, phase):\n#         self.running_loss += loss.item() * inputs1.size(0)\n#         self.running_metric += self.metric(preds, targets).sum()\n#         self.t[phase] += 1\n\n#     def log_epoch(self, phase):\n#         self.epoch_loss[phase] = self.running_loss / self.dataset_sizes[phase]\n#         self.epoch_metric[phase] = self.running_metric / self.dataset_sizes[phase]\n#         self.bar.set_postfix(\n#             a_train_loss=f'{self.epoch_loss[\"train\"]:0.1f}',\n#             b_val_loss=f'{self.epoch_loss[\"val\"]:0.1f}',\n#             c_train_metric=f'{self.epoch_metric[\"train\"]:0.4f}',\n#             d_val_metric=f'{self.epoch_metric[\"val\"]:0.4f}',\n#             es_counter=self.es_counter\n#         )\n#         self.w.add_scalar(\n#             f'Loss/{phase}', self.epoch_loss[phase], self.e[phase])\n#         self.w.add_scalar(\n#             f'Accuracy/{phase}', self.epoch_metric[phase], self.e[phase])\n\n#         self.e[phase] += 1\n\n#         # Early stop and model backup\n#         early_stop = False\n#         if phase == 'val':\n#             if self.epoch_loss['val'] < self.best_loss:\n#                 self.best_loss = self.epoch_loss['val']\n#                 self.best_model_wts = copy.deepcopy(self.model.state_dict())\n#                 torch.save(self.best_model_wts, self.model_file)\n#                 self.es_counter = 0\n#             else:\n#                 self.es_counter += 1\n#                 if self.es_counter >= self.es_patience:\n#                     early_stop = True\n#                     self.bar.close()\n\n#         return early_stop\n\n#     @staticmethod\n#     def metric(preds, targets):\n#         sigma = preds[:, 2] - preds[:, 0]\n#         sigma[sigma < 70] = 70\n#         delta = (preds[:, 1] - targets).abs()\n#         delta[delta > 1000] = 1000\n#         return -np.sqrt(2) * delta / sigma - torch.log(np.sqrt(2) * sigma)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# !rm -rf ./logs/ \n# !mkdir ./logs/\n# # Download Ngrok to tunnel the tensorboard port to an external port\n# !wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n# !unzip ngrok-stable-linux-amd64.zip\n# pool = multiprocessing.Pool(processes = 10)\n# results_of_processes = [\n#     pool.apply_async(os.system, args=(cmd, ), callback=None) for cmd in [\n#         f\"tensorboard --logdir {tensorboard_dir}/ --host 0.0.0.0 --port 6006 &\",\n#         \"./ngrok http 6006 &\"\n#     ]\n# ]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n#     \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Load the data\n# autoencoder = AutoEncoder()\n# autoencoder.load_state_dict(torch.load(\n#     pretrained_ae_weigths,\n#     map_location=torch.device('cuda')\n# ))\n# autoencoder.to(device)\n\n# autoencoder.eval()\n\n# models=[]\n# data = ClinicalDataset(\n#     root_dir=root_dir,\n#     ctscans_dir=os.path.join(root_dir,'train'),\n#     cache_dir=cache_dir,\n#     mode='train',\n#     transform=GenerateLatentFeatures(autoencoder,cache_dir, latent_dir,'train')\n# )\n\n# es_patience = 20\n# es_counter=0\n# early_stop=False\n\n# folds=group_kfold(data,n_splits=5)\n\n# t0 = time()\n\n# for fold, (trainset, valset) in enumerate(folds):\n\n# #     trainset, valset = group_split(data, data.raw['Patient'], test_size)\n\n\n#     # Prepare to save model weights\n#     Path(model_dir).mkdir(parents=True, exist_ok=True)\n#     now = datetime.now()\n#     fname = f'{model_name}-{now.year}{now.month:02d}{now.day:02d}.pth'\n#     model_file = Path(model_dir) / fname\n\n#     dataset_sizes = {'train': len(trainset), 'val': len(valset)}\n#     dataloaders = {\n#         'train': DataLoader(trainset, batch_size=batch_size,\n#                             shuffle=True, num_workers=0),\n#         'val': DataLoader(valset, batch_size=batch_size,\n#                           shuffle=False, num_workers=0)\n#     }\n\n#     # Create the model and optimizer\n#     model = QuantModel().to(device)\n#     optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n\n#     # Set global tracking variables\n#     epoch_loss = {'train': np.inf, 'val': np.inf}\n#     epoch_metric = {'train': -np.inf, 'val': -np.inf}\n#     best_loss = np.inf\n#     best_model_wts = None\n#     df = pd.DataFrame(columns=['epoch', 'train_loss', 'val_loss'])\n\n#     # Training loop\n#     for epoch in range(num_epochs):\n#         for phase in ['train', 'val']:\n#             if phase == 'train':\n#                 model.train()  # Set model to training mode\n#             else:\n#                 model.eval()   # Set model to evaluate mode\n\n#             running_loss = 0.0\n#             running_metric = 0.0\n\n#             # Iterate over data\n#             num_samples = 0\n#             bar = tqdm(dataloaders[phase])\n#             for batch in bar:\n#                 bar.set_description(f'Epoch {epoch} {phase}'.ljust(20))\n#                 inputs1 = batch['tabular_features'].float().to(device)\n#                 inputs2 = batch['latent_features'].float().to(device)\n#                 targets = batch['target'].to(device)\n\n#                 # zero the parameter gradients\n#                 optimizer.zero_grad()\n#                 # forward\n#                 # track gradients if only in train\n#                 with torch.set_grad_enabled(phase == 'train'):\n#                     preds = model(inputs1, inputs2)\n#                     loss = quantile_loss(preds, targets, quantiles)\n#                     # backward + optimize only if in training phase\n#                     if phase == 'train':\n#                         loss.backward()\n\n\n#                         optimizer.step()\n\n#                 running_loss += loss.item() * inputs1.size(0)\n#                 running_metric += metric(preds, targets).sum()\n\n#                 # batch statistics\n#                 num_samples += inputs1.size(0)\n#                 bar.set_postfix(loss=f'{running_loss / num_samples:0.1f}',\n#                                 metric=f'{running_metric / num_samples:0.4f}')\n\n#             # epoch statistics\n#             epoch_loss[phase] = running_loss / dataset_sizes[phase]\n#             epoch_metric[phase] = running_metric / dataset_sizes[phase]\n\n#             # deep copy the model\n#             if phase == 'val' and epoch_loss['val'] < best_loss:\n#                 best_loss = epoch_loss['val']\n#                 best_model_wts = copy.deepcopy(model.state_dict())\n#                 torch.save(best_model_wts, model_file)\n#                 es_counter = 0\n#             else:\n#                 es_counter += 1\n#                 if es_counter >= es_patience:\n#                     early_stop = True\n#                     bar.close()\n\n#         df = df.append({\n#             'epoch': epoch + 1,\n#             'train_loss': epoch_loss[\"train\"],\n#             'val_loss': epoch_loss[\"val\"]\n#         }, ignore_index=True)\n        \n# #         early_stop = log_epoch(data,phase)\n        \n#         if early_stop:\n#             break\n#     # Save training statistics\n#     # fname = f'{model_name}-{now.year}{now.month:02d}{now.day:02d}.csv'\n#     # csv_file = os.path.join(model_dir,fname)\n#     # df.to_csv(csv_file, index=Falsex\n\n#     # load best model weights\n#     model.load_state_dict(best_model_wts)\n\n#     models.append(model)\n\n# print(f'Training complete! Time: {timedelta(seconds=time() - t0)}')\n# # models = [model]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# models = []\n\n# # Load the data\n# # data = ClinicalDataset(root_dir=root_dir, mode='train')\n# autoencoder = AutoEncoder()\n# autoencoder.load_state_dict(torch.load(\n#     pretrained_ae_weigths,\n#     map_location=torch.device('cuda')\n# ))\n# autoencoder.to(device)\n\n# autoencoder.eval()\n\n# models=[]\n# data = ClinicalDataset(\n#     root_dir=root_dir,\n#     ctscans_dir=os.path.join(root_dir,'train'),\n#     cache_dir=cache_dir,\n#     mode='train',\n#     transform=GenerateLatentFeatures(autoencoder,cache_dir, latent_dir,'train')\n# )\n\n# folds=group_kfold(data,n_splits=5)\n# t0 = time()\n\n# for fold, (trainset, valset) in enumerate(folds):\n#     # Prepare to save model weights\n#     Path(model_dir).mkdir(parents=True, exist_ok=True)\n#     now = datetime.now()\n#     fname = f'{model_name}-{now.year}{now.month:02d}{now.day:02d}_{fold}.pth'\n#     model_file = Path(model_dir) / fname\n\n#     dataset_sizes = {'train': len(trainset), 'val': len(valset)}\n#     dataloaders = {\n#         'train': DataLoader(trainset, batch_size=batch_size,\n#                             shuffle=True, num_workers=0),\n#         'val': DataLoader(valset, batch_size=batch_size,\n#                           shuffle=False, num_workers=0)\n#     }\n\n#     # Create the model and optimizer\n#     device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n#     model = QuantModel().to(device)\n#     optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n#     scheduler = StepLR(optimizer, step_size=20, gamma=0.5)\n#     monitor = Monitor(\n#         model=model,\n#         es_patience=es_patience,\n#         experiment_name=f'{model_name}_fold_{fold}',\n#         tensorboard_dir=Path(tensorboard_dir),\n#         num_epochs=num_epochs,\n#         dataset_sizes=dataset_sizes,\n#         model_file=model_file\n#     )\n\n#     # Training loop\n#     for epoch in monitor.bar:\n#         for phase in ['train', 'val']:\n#             if phase == 'train':\n#                 model.train()  # Set model to training mode\n#             else:\n#                 model.eval()   # Set model to evaluate mode\n\n#             monitor.reset_epoch()\n\n#             # Iterate over data\n#             for batch in dataloaders[phase]:\n#                 inputs1 = batch['tabular_features'].float().to(device)\n#                 inputs2 = batch['latent_features'].float().to(device)\n#                 targets = batch['target'].to(device)\n\n#                 # zero the parameter gradients\n#                 optimizer.zero_grad()\n#                 # forward\n#                 # track gradients if only in train\n#                 with torch.set_grad_enabled(phase == 'train'):\n#                     preds = model(inputs1,inputs2)\n#                     loss = quantile_loss(preds, targets, quantiles)\n#                     # backward + optimize only if in training phase\n#                     if phase == 'train':\n#                         loss.backward()\n#                         optimizer.step()\n\n#                 monitor.step(loss, inputs1,inputs2, preds, targets, phase)\n\n#             # epoch statistics\n#             early_stop = monitor.log_epoch(phase)\n\n#         if early_stop:\n#             break\n\n#         # Updates the learning rate\n#         scheduler.step()\n\n#     # load best model weights\n#     model.load_state_dict(monitor.best_model_wts)\n#     models.append(model)\n\n# print(f'Training complete! Time: {timedelta(seconds=time() - t0)}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Generate Submission CSV"},{"metadata":{"trusted":true},"cell_type":"code","source":"# data = ClinicalDataset(\n#     root_dir=root_dir,\n#     ctscans_dir=os.path.join(root_dir,'test'),\n#     mode='test',\n#     transform=transforms.Compose([\n#         CropBoundingBox(),\n#         ConvertToHU(),\n#         Resize((40, 256, 256)),\n#         Clip(bounds=clip_bounds),\n#         MaskWatershed(\n#             min_hu=min(clip_bounds),\n#             iterations=watershed_iterations,\n#             show_tqdm=False),\n#         Normalize(bounds=clip_bounds),\n#         ToTensor(),\n#          ZeroCenter(pre_calculated_mean=pre_calculated_mean)\n#     ]))\n\n# data.cache(latent_dir)                         ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"autoencoder = AutoEncoder()\nautoencoder.load_state_dict(torch.load(\n    pretrained_ae_weigths,\n    map_location=torch.device('cuda')\n))\n# print(pretrained_ae_weigths.shape)\nautoencoder.to(device)\nautoencoder.eval()\n\ndata = ClinicalDataset(\n    root_dir=root_dir,\n    ctscans_dir=os.path.join(root_dir,'test'),\n    cache_dir=\"/kaggle/working/test_cache\",\n    mode='test',\n    transform=GenerateLatentFeatures(autoencoder,\"/kaggle/working/test_cache\",\"/kaggle/working/test_latent\",'test')\n)\nfor i in trange(len(data)):\n    sample = data[i]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# raw=check_submit()\n\n# avg_preds = np.zeros((len(data), len(quantiles)))\n\n# df = pd.DataFrame(data=avg_preds, columns=list(quantiles))\n# df['Patient_Week'] = raw['Patient_Week']\n# df['FVC'] = 5000.0\n# df['Confidence'] = 500.0\n# df = df.drop(columns=list(quantiles))\n# df.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# data = ClinicalDataset(\n#     root_dir=root_dir,\n#     ctscans_dir=os.path.join(root_dir,'test'),\n#     cache_dir=latent_dir,\n#     mode='test',\n#     transform=GenerateLatentFeatures(autoencoder, latent_dir)\n# )\n\n# data = ClinicalDataset(\n#     root_dir=root_dir,\n#     ctscans_dir=os.path.join(root_dir,'test'),\n#     cache_dir=\"/kaggle/working/test_cache\",\n#     mode='test',\n#     transform=GenerateLatentFeatures(autoencoder,'/kaggle/working/test_latent')\n# )\n\nautoencoder = AutoEncoder()\nautoencoder.load_state_dict(torch.load(\n    pretrained_ae_weigths,\n    map_location=torch.device('cuda')\n))\n# print(pretrained_ae_weigths.shape)\nautoencoder.to(device)\nautoencoder.eval()\n\ndata = ClinicalDataset(\n    root_dir=root_dir,\n    ctscans_dir=os.path.join(root_dir,'test'),\n    cache_dir=\"/kaggle/working/test_cache\",\n    mode='test',\n    transform=GenerateLatentFeatures(autoencoder,\"/kaggle/working/test_cache\",\"/kaggle/working/test_latent\",'test')\n)\n\navg_preds = np.zeros((len(data), len(quantiles)))\n\nfor model in models:\n    dataloader = DataLoader(data, batch_size=batch_size,\n                            shuffle=False, num_workers=0)\n    preds = []\n    for batch in tqdm(dataloader):\n#         inputs1 = batch['tabular_features'].float().to(device)\n#         inputs2 = batch['latent_features'].float().to(device)\n        inputs1 = batch['tabular_features'].float().to(device)\n        inputs2 = batch['latent_features'].float().to(device)\n#         targets = batch['target'].to(device)\n        with torch.no_grad():\n            out=model(inputs1, inputs2).cpu()\n            preds.append(out)\n    preds = torch.cat(preds, dim=0).numpy()\n#     preds=preds.numpy()\n    avg_preds += preds\n\navg_preds /= len(models)\ndf = pd.DataFrame(data=avg_preds, columns=list(quantiles))\ndf['Patient_Week'] = data.raw['Patient_Week']\ndf['FVC'] = df[quantiles[1]]\ndf['Confidence'] = df[quantiles[2]] - df[quantiles[0]]\ndf = df.drop(columns=list(quantiles))\ndf.to_csv('submission.csv', index=False)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}